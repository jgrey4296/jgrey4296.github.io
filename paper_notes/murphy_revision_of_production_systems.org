*  Revision of Production System Rule-Bases
** Tags                 :constraints:rules:revision:production_systems:CLIPS:
** Citation: Murphy2014
** YEAR : 2014
** AUTHORS
   Patrick M. Murphy
   Michael J. Pazzani
** ABSTRACT
   We describe CLIPS-R, a theory revision system for the revision of CLIPS
   rule-bases. CLIPS-R differs from previous theory revision systems in that it
   operates on forward chaining production systems. Revision of production system
   rule-bases is important because production systems can perform a variety of
   tasks such as monitoring and design in addition to classification tasks that
   have been addressed by previous research. We show that CLIPS-R can take
   advantage of a variety of user specified constraints on the correct
   processing of instances, such as ordering constraints on the displaying of
   information, and the contents of the final fact list. In addition, we show that
   CLIPS-R can operate as well as existing systems when the only constraint on
   processing an instance is the correct classification of the instance.

** References to others
   Theory revision: Ourston & Mooney, 1990; Pazzani & Brunk, 1991; Wogulis & Pazzani, 1993.

   Trie structure (Fredkin, 1960).

   Prior Prodcution Systems: PSG (Newell & McDer- mott, 1975), OPS (Forgy &
   McDermott, 1976) and PRISM (Langley & Neches, 1981).

   Some systems had multiple working memories, e.g. ACTE (Anderson, 1976)

   Previous work on learning included generalization and discrimination
   (specialization) of rules, e.g. PRISM (Langley, 1987),
   and composition of rules, e.g. Lewis (1978).


** Theory Revision
   Most logical theory revision systems take as input a theory and a set of
   instances that are not fully consistent with the theory.

   Theory revision systems typically have an iterative refinement control
   structure that includes: identification of a set of likely repairs (usually
   done through an abductive process) and evaluation of the repairs over the
   set of instances.

   CLIPS-R has *operators for specialization and generalization*.
   Heuristically identifies problem instances
   -> potential repairs
   -> evaluates
   -> induces new rule

   An instance used by CLIPS-R has two components: initial state information and
   constraints on the execution of the rule-base given the initial state.

   Constraints on the ordering of the execution of observable actions, are
   represented using a finite state machine. Ordering constraints are
   satisfied when the sequence of observable actions, formed from the execution
   of an instance, is accepted by the finite state machine associated with that
   instance.

   Individual instances in CLIPS-R are each given an error score that ranges from
   0 to 1. The error of an individual instance is simply the number of constraint
   violations divided by the total number of possible constraint violations. The
   error score for multiple instances is the average of their individual error
   scores.

   The trie structure is a compact representation of all of the rule traces that
   groups together those instances that share an initial sequence of rule firings.
   Each leaf stores the set of instances with the same sequence of rule firings.
   Associated with each instance is its individual error rate as well as an
   augmented trace of rule firings (see section 3.6). In addition, associated with
   each internal node of the trie is a sum of the number of errors of all
   instances with rule firing sequences that share that node and a sum of the
   total number of possible errors. An error rate for each node is obtained by
   dividing the total number of errors at the node by the total number of
   possible errors at the node. Figure 4 shows an example trie that summarizes
   five instances processed using the incorrect student loan rule-base. Nine
   constraints were evaluated for each instances, and the three numbers (e.g.
   [6,45,0.133]) associated with each node are the total number of errors, the
   total possible number of errors and the error rate, respectively, at that
   node.

   In order to simplify the description of the specialization and generalization
   operators, it is useful to conceptualize the set of conditional elements in a
   rule as a single Boolean expression. Given this representation, specialization
   is accomplished by either conjoining a primitive conditional element to a
   term in the expression or by deleting a disjunct from the expression.
   Generalization is accomplished by either disjoining a primitive conditional
   element to a term in the expression or by deleting a conjunct from the
   expression.

   Action promotion and demotion.
   Assert / Retract addition.
   Observable action modification.
   Changing rule salience.
   Rule Deletion.

   Repair identification heuristics are used to suggest a set of operators that
   should be attempted to improve the rule-base. There are two sets of
   heuristics that may be used: final factlist heuristics suggest how to
   correct errors when the assertions (e.g., the class of the instance) made
   when processing an instance, do not agree with the desired assertions.
   Ordering constraint violation heuristics suggest how to correct errors when
   observables are omitted or occur in the wrong order. If both kinds of
   violations occur, then both kinds of heuristics suggest repairs and the best
   repair is made.

   The trace information includes:
   1) The sequence of rule firings.
   2) A copy of the fact-list prior to each rule firing.
   3) A copy of the final fact-list.
   4) Lists of actions executed by each rule firing.
   5) Information associating a fact and its source (i.e. an assert action).
   6) Information associating a retract action and the fact that it retracted.
   7) Information associating the positive pattern conditional elements of each
      fired rule and the facts that matched them.

   Constraint violations on the final fact-list are in the form of extra
   ground facts and missing conditions (i.e., a general pattern that should
   unify with a ground fact in the fact-list).

   Rule Induction:
   When other repair operators fail, an attempt is made to induce a new rule to
   solve some final fact-list constraint violation. A sampling of rules are
   first generated then, in turn, revised through a local hill-climbing iterative
   refinement search. The rule with the lowest error when added to the rule-base is
   added. Initial rules are generated in the following manner. The LHS of the
   rule is formed by taking the least general generalization (Plotkin, 1970) of the
   initial fact-lists for a pair of instances that have similar final fact-list
   constraint violations. If the common constraint violation corresponds to a
   positive constraint (e.g. a missing condition in the final fact-list) the RHS of
   the rule contains a single assert of the missing condition. Similarly, if the
   final fact-list constraint violation corresponds to a negative constraint (e.g.
   an extra fact in the final fact-list) the RHS contains a single retract for the
   extra fact.


** Summary
   The general goal of (theory revision) is to create learning models that can
   automatically update the knowledge base of a system to be more accurate on a
   set of test cases.

   There are a variety of practical reasons that the production rule formalism is
   preferred to the logical rule formalism in deployed expert systems.

   First, production rules are suitable for a variety of reasoning tasks, such as
   planning, design and scheduling in addition to classification tasks that are
   addressed by logical rules.

   Second, most deployed knowledge-based systems must perform a variety of
   computational activities such as interacting with external databases or
   printing reports in addition to the “reasoning” tasks.
   The production system formalism allows such procedural tasks to be easily
   combined with the reasoning tasks.

   Third, the production rule systems tend to be computationally more efficient.

   CLIPS is similar to a variety of production system languages, in that it has a
   rule-base, an agenda (an ordered sequence of rule activations), and a fact-list
   (working memory)




*** Research Questions

*** Hypothesis tested

*** Methods

    The student loan domain consists of a set of nine rules (rep- resented as Horn
    clauses) and a set of 1000 instances. The rule-base contains four errors (an
    extra literal, a missing literal, an extra clause and a missing clause). This
    initial theory has an error of 21.6%. In order to use this rule-base with
    CLIPS-R, the nine Horn clause rules were converted into nine production rules,
    each with a single assert action. Multiple clauses in the Horn clause rules were
    converted to a disjunction of conjuncts within a CLIPS production rule.


    The auto diagnosis rule-base (provided with the CLIPS software) uses features of
    CLIPS not easily expressed in pure Horn clauses. It is an expert system that
    prints out an introductory message, asks a series of questions of the user, and
    prints out a concluding message including the predicted diagnosis. This
    rule-base has a total of 15 rules.

*** Results

*** Authors key findings

*** Contributions [Faster/Cheaper/Better]
    Describes CLIPS-R for rule revision
    Evaluates CLIPS-R on student load problem


** What kind of text is it?

** What genre is the text?

** What is the critical context?

** What is the intended audience?

** What is your purpose in reading?

** What are you meant to get out of the text?
*** Are you supposed to get the gist, or details?

*** Are you meant to close read the language of the text?

*** Are you meant to apply or relate the text to something else?

*** Are you supposed to engage with (agree, disagree, tweak, nuance) the text?

** What it says / What it does
   For each chapter/section/subsection/paragraph
*** What it Says: Stated or implied topic

*** What it Does: Function within the reading
    Evidence for claim, summarize opposing view, data, analogy etc.

** Double Entry
*** Represent the text in your own words. Restate the argument.

*** Respond to the text.
    Analyse, relate, question, believe, doubt, refute, go beyond.

** Believe / Doubt
   Read with opposing views.
*** Believing - Read generously

*** Doubting  - Read critically

** Reverse Outline
   Organise text hierarchically by function

** Freewrite argumentative response
*** Before I read this text, the author assumed I knew and believed X

*** After I Read this text, the author wanted me to think and believe that Y

*** The Author was (not) successful in changing my views. How so, and why.
