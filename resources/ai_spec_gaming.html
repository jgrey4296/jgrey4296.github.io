<!DOCTYPE html><html><head><title>Specification gaming examples in AI - master list</title><meta name="viewport" content="target-densitydpi=device-dpi,user-scalable=1,minimum-scale=1,maximum-scale=2.5,initial-scale=1,width=device-width"><link href='/static/spreadsheets2/client/css/647005191-waffle_k_ltr.css' type='text/css' rel='stylesheet'><style type="text/css" nonce="8pNGRxifUUMi3RSk3NTiDg">
        html { overflow: visible; }
        #sheets-viewport { overflow: auto; }
        #sheets-viewport.widget-viewport { overflow: hidden; }
        .grid-container { overflow: visible; background: white;}
        .grid-table-container { overflow: visible; }
        #top-bar {
          background: url("//ssl.gstatic.com/docs/spreadsheets/publishheader.png") repeat-x bottom;
          margin: 0;
          overflow: hidden;
        }
        #top-bar {
          border-bottom: 1px solid #ccc;
          padding: 6px 6px 0;
        }
        #doc-title { padding-bottom: 5px; }
        #doc-title .name { font-size: 15px; }
        #sheet-menu {
          font-size: 13px;
          margin: 6px 0 0;
          padding: 0 0 5px;
        }
        #sheet-menu li {
          display: inline;
          list-style-type: none;
          margin: 0;
          padding: 5px 8px;
        }
        #sheet-menu li.active {
          background-color: #fff;
          font-weight: bold;
          border: 1px solid #999;
        }
        #top-bar #sheet-menu li.active {
          border-bottom: 0;
        }
        #sheet-menu a, #sheet-menu a:visited { color: #07c; }
        #footer {
          background: #f0f0f0;
          border-top: 1px #ccc solid;
          border-bottom: 1px #ccc solid;
          font-size: 13;
          padding: 10px 10px;
        }
        .dash {
          padding: 0 6px;
        }
        .ritz .waffle a { color: inherit; }.ritz .waffle .s2{background-color:#f9cb9c;text-align:left;font-style:italic;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#1155cc;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;overflow:hidden;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s8{background-color:#ffffff;text-align:left;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;overflow:hidden;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s4{background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s9{background-color:#ffffff;text-align:left;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s5{background-color:#ffffff;text-align:left;font-weight:bold;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;overflow:hidden;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s0{background-color:#f9cb9c;text-align:left;font-style:italic;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s3{background-color:#f9cb9c;text-align:left;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s7{background-color:#ffffff;text-align:left;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#1155cc;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;overflow:hidden;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s6{background-color:#ffffff;text-align:left;color:#000000;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:normal;overflow:hidden;word-wrap:break-word;direction:ltr;padding:2px 3px 2px 3px;}.ritz .waffle .s1{background-color:#f9cb9c;text-align:left;font-style:italic;text-decoration:underline;-webkit-text-decoration-skip:none;text-decoration-skip-ink:none;color:#1155cc;font-family:'Arial';font-size:11pt;vertical-align:bottom;white-space:nowrap;direction:ltr;padding:2px 3px 2px 3px;}</style><script type="text/javascript" nonce="8pNGRxifUUMi3RSk3NTiDg">
        var activeSheetId;

        function switchToSheet(id) {
          if (document.getElementById('sheet-menu')) {
            document.getElementById('sheet-button-' + activeSheetId)
                .className = '';
            document.getElementById('sheet-button-' + id).className = 'active';
          }

          document.getElementById(activeSheetId).style.display = 'none';
          document.getElementById(id).style.display = '';
          activeSheetId = id;

          // posObjs() is defined in embeddedObjectJs (see EmbeddedObjectHtmlBuilder.java)
          posObjs();
          return false;
        }
        
        function init() {
        var optPageSwitcher;
        
        function resize() {
          var optMobileWebHeader = document.getElementById('docs-ml-header-id');
          var optTopBar = document.getElementById('top-bar');
          var optFooter = document.getElementById('footer');
          var sheetsViewport = document.getElementById('sheets-viewport');

          if (optMobileWebHeader) {
            sheetsViewport.style.marginTop = optMobileWebHeader.offsetHeight +
                (optTopBar ? optTopBar.offsetHeight : 0) + 'px';
          }
          var adjustedHeight = window.innerHeight -
              (optTopBar ? optTopBar.offsetHeight : 0) -
              (optFooter ? optFooter.offsetHeight : 0);
          var adjustedWidth = window.innerWidth;
          sheetsViewport.style.width = (adjustedWidth + 'px');
          sheetsViewport.style.height = (adjustedHeight + 'px');
          if (optPageSwitcher) {
            optPageSwitcher.resize(adjustedWidth, adjustedHeight);
          }
        }
        resize();
        window.onresize = resize;
        }
        </script><script nonce="8pNGRxifUUMi3RSk3NTiDg">_docs_flag_initialData={"docs-mwid":true,"docs-smheo":true,"info_params":{"includes_info_params":true},"ilcm":{"eui":"ADFN-ct0eRq9n76I6dhxx30IxKHs3lOtKAmmjH6P3UneNzjqgNomPGMRd50reXH940fp4x1k1lpZ","je":1,"sstu":1579116210581000,"si":"CN3cqaaqhucCFQlBnQod3TQBwQ","gsc":0,"ei":[5703182,5706161,5708838,5701030,5706645,5706359,5703913,5705895,5707445,5707625,5708878,5704585,5701853,5704399,5700933,5703839,5708826,5708946,5702556,5707161,5701963,5703391,5705533,5708449,5704289,5708061,5707165,5707177,5705461,5706471,5706363,5705697,5709697,5702459,5701536,5700680,5707657,5704039,5701574,5703871,5703202,5706601,5701461,5709286,5703745,5704661,5703762,5703210,5700446,5705147,5702849,5707091,5701870,5703112,5704887,5704943,5705777,5707757,5708950,5700876,5701453,5706933,5705545,5706101,5707117,5704883,5709141,5703705,5702301,5704403,5706375,5701067,5702628,5704785,5706391,5706315,5700752,5706467,5700884,5707063,5702332,5702728,5704148,5706661,5700650,5701761,5707051,5704144,5704063,5707796,5702632,5706657,5705047,5703319,5704301,5701602,5706229,5702636,5704879,5704273,5708462,5708325,5706403,5708695,5706121,5704436,5701626,5705235,5703479,5702785,5708353,5707209,5705858,5708127,5701844,5704729,5706270,5703347,5703022,5707331,5706261,5704633,5700998,5704269,5707059,5702027,5703186,5705705,5709065,5705179,5703539,5705653,5706523,5704391,5708223,5700808,5705027,5704641,5709413,5702023,5708584,5709436,5708882,5704285,5703323,5705581,5705625,5701393,5703190,5704544,5705043,5704096,5701445,5706015,5707715,5704281,5706641,5700100,5702640,5701731,5703615,5707605,5704567,5704027,5705883,5708846,5709739,5704581,5706081,5703543,5706924,5704480,5703819,5706073,5703014,5703792,5707357,5704253,5703879,5704625,5707949,5704645,5708930,5705557,5703693,5703815,5705183,5706989,5703355,5705040,5706069,5704047,5709185,5707711,5706003,5703754,5706011,5702445,5707965,5700138,5702011,5708393,5700016,5706077,5704160,5705621,5701650,5704444,5708490,5707241,5703054,5701437,5705489,5700358,5703419,5705215,5701532,5701915,5703750,5706791,5700559,5705887,5707765,5705131,5706589,5700019,5703006,5704899,5706884,5704448,5706920,5703661,5704528,5705927,5706125,5705091,5701034,5709197,5706319,5706621,5706711,5707737,5707289,5706055,5704561,5706423,5707844,5705075,5704257,5701022,5703027,5709014,5705915,5707840,5702441,5706061,5700551,5704939,5705231,5705809,5703339,5702097,5707345,5705023,5707943,5704907,5701558,5703837,5702936,5706355,5705223,5707741,5701594,5702135,5705421,5708349,5708954,5704196,5700937,5707870,5705299,5704665,5707397,5700250,5705947,5707425,5702873,5707832,5705329,5707986,5705313,5706007,5707525,5707413,5704055,5701967,5702912,5708516,5702706,5703535,5703591,5708037,5701220,5708512,5704553,5705103,5705805,5701820,5706507,5706133,5704371,5706286,5706093,5706109,5707047,5701433,5708494,5703259,5705317,5707197,5703451,5700422,5709133,5709161,5705585,5704431,5701889],"crc":0,"cvi":[]},"drive_url":"//drive.google.com?usp\u003dsheets_web","docs-sup":"/spreadsheets"}; _docs_flag_cek= null ;</script></head><script nonce="8pNGRxifUUMi3RSk3NTiDg">document.addEventListener('DOMContentLoaded', init);</script><body><div id="top-bar"><div id="doc-title"><span class="name">Specification gaming examples in AI - master list : Sheet1</span></div></div><div id="sheets-viewport"><div id="0" style="display:none;position:relative;" dir="ltr"><div class="ritz grid-container" dir="ltr"><table class="waffle" cellspacing="0" cellpadding="0"><thead><tr><th class="row-header freezebar-vertical-handle header-shim row-header-shim"></th><th id="0C0" style="width:156px" class="header-shim"></th><th id="0C1" style="width:405px" class="header-shim"></th><th id="0C2" style="width:161px" class="header-shim"></th><th id="0C3" style="width:324px" class="header-shim"></th><th id="0C4" style="width:154px" class="header-shim"></th><th id="0C5" style="width:116px" class="header-shim"></th><th id="0C6" style="width:171px" class="header-shim"></th><th id="0C7" style="width:100px" class="header-shim"></th><th id="0C8" style="width:100px" class="header-shim"></th><th id="0C9" style="width:100px" class="header-shim"></th><th id="0C10" style="width:100px" class="header-shim"></th><th id="0C11" style="width:100px" class="header-shim"></th><th id="0C12" style="width:100px" class="header-shim"></th><th id="0C13" style="width:100px" class="header-shim"></th><th id="0C14" style="width:100px" class="header-shim"></th><th id="0C15" style="width:100px" class="header-shim"></th><th id="0C16" style="width:100px" class="header-shim"></th><th id="0C17" style="width:100px" class="header-shim"></th><th id="0C18" style="width:100px" class="header-shim"></th><th id="0C19" style="width:100px" class="header-shim"></th><th id="0C20" style="width:100px" class="header-shim"></th><th id="0C21" style="width:100px" class="header-shim"></th><th id="0C22" style="width:100px" class="header-shim"></th><th id="0C23" style="width:100px" class="header-shim"></th><th id="0C24" style="width:100px" class="header-shim"></th><th id="0C25" style="width:100px" class="header-shim"></th><th id="0C26" style="width:100px" class="header-shim"></th><th id="0C27" style="width:100px" class="header-shim"></th></tr></thead><tbody><tr style='height:20px;'><th id="0R0" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">1</div></th><td class="s0"></td><td class="s0" dir="ltr">Submit more examples through this Google form:</td><td class="s1 softmerge" dir="ltr"><div class="softmerge-inner" style="width: 158px; left: -1px;"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://docs.google.com/forms/d/e/1FAIpQLSeQEguZg4JfvpTywgZa3j-1J-4urrnjBVeoAO7JHIH53nrBTA/viewform&amp;sa=D&amp;ust=1579119810618000&amp;usg=AFQjCNHEUEiXO1mB-NL8FTDurEHExHoDSg">https://docs.google.com/forms/d/e/1FAIpQLSeQEguZg4JfvpTywgZa3j-1J-4urrnjBVeoAO7JHIH53nrBTA/viewform</a></div></td><td class="s0" dir="ltr">More information in this blog post:</td><td class="s2" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/&amp;sa=D&amp;ust=1579119810618000&amp;usg=AFQjCNEUNBDoH_0GlF6RqHtAuYxMjmY8HA">https://vkrakovna.wordpress.com/2018/04/02/specification-gaming-examples-in-ai/</a></td><td class="s0"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td><td class="s3"></td></tr><tr style='height:20px;'><th id="0R1" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">2</div></th><td class="s4" dir="ltr">Title</td><td class="s4" dir="ltr">Description</td><td class="s4" dir="ltr">Authors</td><td class="s4" dir="ltr">Original source</td><td class="s5" dir="ltr">Original source link</td><td class="s5" dir="ltr">Video / Image</td><td class="s4" dir="ltr">Source / Credit</td><td class="s5" dir="ltr">Source link</td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td><td class="s5"></td></tr><tr><th style="height:3px" class="freezebar-cell freezebar-horizontal-handle row-header-shim"></th><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td><td class="freezebar-cell"></td></tr><tr style='height:20px;'><th id="0R2" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">3</div></th><td class="s6" dir="ltr">Aircraft landing</td><td class="s6" dir="ltr">Evolved algorithm for landing aircraft exploited overflow errors in the physics simulator by creating large forces that were estimated to be zero, resulting in a perfect score</td><td class="s6" dir="ltr">Feldt, 1998</td><td class="s6" dir="ltr">Generating diverse software versions with genetic programming: An experimental study.</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://ieeexplore.ieee.org/document/765682/&amp;sa=D&amp;ust=1579119810620000&amp;usg=AFQjCNF-pIPVJrDRjmolVGdmvxHCBeEKfA">http://ieeexplore.ieee.org/document/765682/</a></td><td class="s8"></td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810620000&amp;usg=AFQjCNEusn1XBihuOGAYXtk_q479UtZJbA">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R3" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">4</div></th><td class="s6">Bicycle</td><td class="s6" dir="ltr">Reward-shaping a bicycle agent for not falling over &amp; making progress towards a goal point (but not punishing for moving away) leads it to learn to circle around the goal in a physically stable loop.</td><td class="s6">Randlov &amp; Alstrom, 1998</td><td class="s6">Learning to Drive a Bicycle using Reinforcement Learning and Shaping</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://pdfs.semanticscholar.org/10ba/d197f1c1115005a56973b8326e5f7fc1031c.pdf&amp;sa=D&amp;ust=1579119810621000&amp;usg=AFQjCNFkEhj6AXhQJsjerto5KrtCWzfjew">https://pdfs.semanticscholar.org/10ba/d197f1c1115005a56973b8326e5f7fc1031c.pdf</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810621000&amp;usg=AFQjCNFdo8DIBP9ATDvtrh1xZWs6NfdBgw">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R4" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">5</div></th><td class="s6" dir="ltr">Block moving</td><td class="s6" dir="ltr">A robotic arm trained to slide a block to a target position on a table achieves the goal by moving the table itself.</td><td class="s6" dir="ltr">Chopra, 2018</td><td class="s6" dir="ltr">GitHub issue for OpenAI gym environment FetchPush-v0</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://github.com/openai/gym/issues/920&amp;sa=D&amp;ust=1579119810621000&amp;usg=AFQjCNF8nuRXn7lD2Aysehsn5UrCnWNpTQ">https://github.com/openai/gym/issues/920</a></td><td class="s8"></td><td class="s6" dir="ltr">Matthew Rahtz</td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R5" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">6</div></th><td class="s6">Boat race</td><td class="s6">The agent goes in a circle hitting the same targets instead of finishing the race</td><td class="s6" dir="ltr">Amodei &amp; Clark, 2016</td><td class="s6">Faulty reward functions in the wild</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://blog.openai.com/faulty-reward-functions/&amp;sa=D&amp;ust=1579119810622000&amp;usg=AFQjCNFUemCZBriGbKZ_ViKOwzLc9SR4Og">https://blog.openai.com/faulty-reward-functions/</a></td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?time_continue%3D1%26v%3DtlOIHko8ySg&amp;sa=D&amp;ust=1579119810622000&amp;usg=AFQjCNFbmnU1VJRtZLE6k555PnkLlE1ujw">https://www.youtube.com/watch?time_continue=1&amp;v=tlOIHko8ySg</a></td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R6" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">7</div></th><td class="s6" dir="ltr">Ceiling</td><td class="s6" dir="ltr">A genetic algorithm was instructed to try and make a creature stick to the ceiling for as long as possible. It was scored with the average height of the creature during the run. Instead of sticking to the ceiling, the creature found a bug in the physics engine to snap out of bounds.</td><td class="s6" dir="ltr">Higueras, 2015</td><td class="s6" dir="ltr">Genetic Algorithm Physics Exploiting</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://youtu.be/ppf3VqpsryU&amp;sa=D&amp;ust=1579119810623000&amp;usg=AFQjCNHt6jHQl7XDe_mPNI6K9hg22PYjZw">https://youtu.be/ppf3VqpsryU</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://youtu.be/ppf3VqpsryU&amp;sa=D&amp;ust=1579119810623000&amp;usg=AFQjCNHt6jHQl7XDe_mPNI6K9hg22PYjZw">https://youtu.be/ppf3VqpsryU</a></td><td class="s6" dir="ltr">Jesús Higueras</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://youtu.be/ppf3VqpsryU&amp;sa=D&amp;ust=1579119810623000&amp;usg=AFQjCNHt6jHQl7XDe_mPNI6K9hg22PYjZw">https://youtu.be/ppf3VqpsryU</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R7" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">8</div></th><td class="s6" dir="ltr">CycleGAN steganography</td><td class="s6" dir="ltr">CycleGAN algorithm for converting aerial photographs into street maps and back steganographically encoded output information in the intermediary image without it being humanly detectable.</td><td class="s6">Chu et al, 2017</td><td class="s6">CycleGAN, a Master of Steganography</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1712.02950&amp;sa=D&amp;ust=1579119810624000&amp;usg=AFQjCNFzic38_9h4u8LlVdgYVFQJmrz3ew">https://arxiv.org/abs/1712.02950</a></td><td class="s8"></td><td class="s8" dir="ltr">Tech Crunch / Gwern Branwen / Braden Staudacher</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://techcrunch.com/2018/12/31/this-clever-ai-hid-data-from-its-creators-to-cheat-at-its-appointed-task/&amp;sa=D&amp;ust=1579119810624000&amp;usg=AFQjCNGl6zCltnsMphUwPfZiS2HQ1ZYLgQ">https://techcrunch.com/2018/12/31/this-clever-ai-hid-data-from-its-creators-to-cheat-at-its-appointed-task/</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R8" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">9</div></th><td class="s6" dir="ltr">Data order patterns</td><td class="s6" dir="ltr">Neural nets evolved to classify edible and poisonous mushrooms took advantage of the data being presented in alternating order, and didn&#39;t actually learn any features of the input images</td><td class="s6" dir="ltr">Ellefsen et al, 2015</td><td class="s6" dir="ltr">Neural modularity helps organisms evolve to learn new skills without forgetting old skills</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://journals.plos.org/ploscompbiol/article?id%3D10.1371/journal.pcbi.1004128&amp;sa=D&amp;ust=1579119810625000&amp;usg=AFQjCNGEJCNvK1UelSZ4f4Ln3vjc63e81w">http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004128</a></td><td class="s8"></td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810625000&amp;usg=AFQjCNFyOKjZy0zKGGYRqNgqWsquD_e6Eg">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R9" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">10</div></th><td class="s6" dir="ltr">Eurisko - authorship</td><td class="s6" dir="ltr">Game-playing agent accrues points by falsely inserting its name as the author of high-value items</td><td class="s6">Johnson, 1984</td><td class="s6">Eurisko, The Computer With A Mind Of Its Own</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://aliciapatterson.org/stories/eurisko-computer-mind-its-own&amp;sa=D&amp;ust=1579119810626000&amp;usg=AFQjCNGNvnBiz283pWvuL39FMyoYoaf7CQ">http://aliciapatterson.org/stories/eurisko-computer-mind-its-own</a></td><td class="s8"></td><td class="s6">Catherine Olsson / Stuart Armstrong</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://lesswrong.com/lw/lvh/examples_of_ais_behaving_badly/&amp;sa=D&amp;ust=1579119810626000&amp;usg=AFQjCNHZUqiB4Vj6C2gDNNeCzqKEWhwrDg">http://lesswrong.com/lw/lvh/examples_of_ais_behaving_badly/</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R10" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">11</div></th><td class="s6" dir="ltr">Eurisko - fleet</td><td class="s6" dir="ltr">Eurisko won the Trillion Credit Squadron (TCS) competition two years in a row creating fleets that exploited loopholes in the game&#39;s rules, e.g. by spending the trillion credits on creating a very large number of stationary and defenseless ships</td><td class="s6" dir="ltr">Lenat, 1983</td><td class="s6">Eurisko, The Computer With A Mind Of Its Own</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://aliciapatterson.org/stories/eurisko-computer-mind-its-own&amp;sa=D&amp;ust=1579119810626000&amp;usg=AFQjCNGNvnBiz283pWvuL39FMyoYoaf7CQ">http://aliciapatterson.org/stories/eurisko-computer-mind-its-own</a></td><td class="s8"></td><td class="s6" dir="ltr">Haym Hirsh</td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R11" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">12</div></th><td class="s6" dir="ltr">Evolved creatures - clapping</td><td class="s6" dir="ltr">Creatures exploit a collision detection bug to get free energy by clapping body parts together</td><td class="s6">Sims, 1994</td><td class="s6">Evolved Virtual Creatures</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.karlsims.com/papers/siggraph94.pdf&amp;sa=D&amp;ust=1579119810627000&amp;usg=AFQjCNG41HW1X5Kr7lE8_NSkK_VL-aGUEA">http://www.karlsims.com/papers/siggraph94.pdf</a></td><td class="s8" dir="ltr"></td><td class="s6" dir="ltr">Lehman et al, 2018; Janelle Shane</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810627000&amp;usg=AFQjCNE_nUEH6bf8ml2Tp3qiKFBhtLCpGw">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R12" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">13</div></th><td class="s6" dir="ltr">Evolved creatures - falling</td><td class="s6" dir="ltr">Creatures bred for speed grow really tall and generate high velocities by falling over</td><td class="s6">Sims, 1994</td><td class="s6">Evolved Virtual Creatures</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.karlsims.com/papers/siggraph94.pdf&amp;sa=D&amp;ust=1579119810628000&amp;usg=AFQjCNEATIXS_RYsa8S9rZB_CnE6Cax0Lg">http://www.karlsims.com/papers/siggraph94.pdf</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://pbs.twimg.com/media/Daq-7wBU8AUlmLK.jpg:large&amp;sa=D&amp;ust=1579119810628000&amp;usg=AFQjCNFsMUxbUV9-0tIq1EHSrRKcmN3GoA">https://pbs.twimg.com/media/Daq-7wBU8AUlmLK.jpg:large</a></td><td class="s6" dir="ltr">Lehman et al, 2018; Janelle Shane</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810628000&amp;usg=AFQjCNGtwThK_jyvB_bljJIgQ9962IuoPw">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R13" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">14</div></th><td class="s6" dir="ltr">Evolved creatures - floor collisions</td><td class="s6" dir="ltr">Creatures exploited a coarse physics simulation by penetrating the floor between time steps without the collision being detected, which generated a repelling force, giving them free energy.</td><td class="s6" dir="ltr">Cheney et al, 2013</td><td class="s6" dir="ltr">Unshackling evolution: evolving soft robots with multiple materials and a powerful generative encoding</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://jeffclune.com/publications/2013_Softbots_GECCO.pdf&amp;sa=D&amp;ust=1579119810629000&amp;usg=AFQjCNHzi3iUL9f449MX4zXIK6d3ojeDcA">http://jeffclune.com/publications/2013_Softbots_GECCO.pdf</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://pbs.twimg.com/media/Daq_9cvU0AAp1Fo.jpg&amp;sa=D&amp;ust=1579119810629000&amp;usg=AFQjCNHSnXYdG7t8H1MDAlkRY9Va57bjdg">https://pbs.twimg.com/media/Daq_9cvU0AAp1Fo.jpg</a></td><td class="s6" dir="ltr">Lehman et al, 2018; Janelle Shane</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810629000&amp;usg=AFQjCNEBp9FNI7Bi2eM5-NeLXGWPxyTuXA">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R14" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">15</div></th><td class="s6" dir="ltr">Evolved creatures - pole vaulting</td><td class="s6" dir="ltr">Creatures bred for jumping were evaluated on the height of the block that was originally closest to the ground. The creatures developed a long vertical pole and flipped over instead of jumping.</td><td class="s6" dir="ltr">Krcah, 2008</td><td class="s6" dir="ltr">Towards efficient evolutionary design of autonomous robots</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://artax.karlin.mff.cuni.cz/~krcap1am/ero/doc/krcah-ices08.pdf&amp;sa=D&amp;ust=1579119810630000&amp;usg=AFQjCNH8bo9ukbGxVp6OAvarcVfY7bOYhA">http://artax.karlin.mff.cuni.cz/~krcap1am/ero/doc/krcah-ices08.pdf</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://pbs.twimg.com/media/Daq_YhBV4AA8NRh.jpg&amp;sa=D&amp;ust=1579119810630000&amp;usg=AFQjCNE5l0AsrsdO7DLP_DnzzK9IQAt-CA">https://pbs.twimg.com/media/Daq_YhBV4AA8NRh.jpg</a></td><td class="s6" dir="ltr">Lehman et al, 2018; Janelle Shane</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810630000&amp;usg=AFQjCNHarMwJCelcsUYy4M9MOHRbHSFHDQ">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R15" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">16</div></th><td class="s6" dir="ltr">Evolved creatures - self-intersection</td><td class="s6" dir="ltr">Creatures exploit a quirk in Box2D physics by clipping one leg into another to slide along the ground with phantom forces instead of walking</td><td class="s6" dir="ltr">Code Bullet</td><td class="s6" dir="ltr">AI Learns To Walk</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://youtu.be/K-wIZuAA3EY?t%3D486&amp;sa=D&amp;ust=1579119810631000&amp;usg=AFQjCNGES2fZAXLzI2VUE_n9pCZnq2kIlA">https://youtu.be/K-wIZuAA3EY?t=486</a></td><td class="s8" dir="ltr"></td><td class="s6" dir="ltr">Peter Cherepanov</td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R16" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">17</div></th><td class="s6" dir="ltr">Evolved creatures - suffocation</td><td class="s6" dir="ltr">In a game meant to simulate the evolution of creatures, the programmer had to remove &quot;a survival strategy where creatures could gain energy by suffocating themselves&quot;</td><td class="s6" dir="ltr">Schumacher, 2018</td><td class="s6" dir="ltr">0.11.0.9&amp;10: All the Good Things</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://speciesdevblog.wordpress.com/2018/10/04/0-11-0-910-all-the-good-things/&amp;sa=D&amp;ust=1579119810631000&amp;usg=AFQjCNHFdyDORyk6CuMZyge2v-3wDOEMMA">https://speciesdevblog.wordpress.com/2018/10/04/0-11-0-910-all-the-good-things/</a></td><td class="s8" dir="ltr"></td><td class="s6" dir="ltr"></td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R17" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">18</div></th><td class="s6" dir="ltr">Evolved creatures - twitching</td><td class="s6" dir="ltr">Creatures exploited physics simulation bugs by twitching, which accumulated simulator errors and allowed them to travel at unrealistic speeds</td><td class="s6">Sims, 1994</td><td class="s6">Evolved Virtual Creatures</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.karlsims.com/papers/siggraph94.pdf&amp;sa=D&amp;ust=1579119810632000&amp;usg=AFQjCNGzDaWYV5_tqPiSLvoM7fNTmdvtUA">http://www.karlsims.com/papers/siggraph94.pdf</a></td><td class="s8" dir="ltr"></td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810632000&amp;usg=AFQjCNFU8OB5EVLchmewlnCQJaHoYJ3ntg">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R18" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">19</div></th><td class="s6" dir="ltr">Go pass</td><td class="s6" dir="ltr">A reimplementation of AlphaGo learns to pass forever if passing is an allowed move</td><td class="s6" dir="ltr">Chew, 2019</td><td class="s6" dir="ltr">A Funny Thing Happened On The Way to Reimplementing AlphaGo in Go</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://speakerdeck.com/chewxy/a-funny-thing-happened-on-the-way-to-reimplementing-alphago-in-go?slide%3D142&amp;sa=D&amp;ust=1579119810633000&amp;usg=AFQjCNFvS4lKxe0mV9j86AaZoi40K9kLVw">https://speakerdeck.com/chewxy/a-funny-thing-happened-on-the-way-to-reimplementing-alphago-in-go?slide=142</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dnk87zsxpF1A&amp;sa=D&amp;ust=1579119810633000&amp;usg=AFQjCNF4DHnAYVknZplRDvGhFz_ub_BicQ">https://www.youtube.com/watch?v=nk87zsxpF1A</a></td><td class="s6" dir="ltr">Anonymous form submission</td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R19" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">20</div></th><td class="s6" dir="ltr">Gripper</td><td class="s6" dir="ltr">A robot arm with a purposely disabled gripper found a way to hit the box in a way that would force the gripper open</td><td class="s6" dir="ltr">Ecarlat et al, 2015</td><td class="s6" dir="ltr">Learning a high diversity of object manipulations through an evolutionary-based babbling</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.isir.upmc.fr/files/2015ACTI3564.pdf&amp;sa=D&amp;ust=1579119810634000&amp;usg=AFQjCNFepVydcJHMyWy7tcjb2d8ze-Qoyw">http://www.isir.upmc.fr/files/2015ACTI3564.pdf</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D_5Y1hSLhYdY%26feature%3Dyoutu.be&amp;sa=D&amp;ust=1579119810634000&amp;usg=AFQjCNEruMBngW6WPJlwjbd6_SEIuLjchA">https://www.youtube.com/watch?v=_5Y1hSLhYdY&amp;feature=youtu.be</a></td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810634000&amp;usg=AFQjCNH0CbXKD35SAeDSBSaZZ4SeTIr1zA">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R20" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">21</div></th><td class="s6" dir="ltr">Hide-and-seek</td><td class="s6" dir="ltr">Agents playing a hide-and-seek game find various ways to exploit the physics simulator:<br>- Box surfing: Since agents move by applying forces to themselves, they can grab a box while on top of it and “surf” it to the hider’s location.<br>- Endless running: Without adding explicit negative rewards for agents leaving the play area, in rare cases hiders will learn to take a box and endlessly run with it.<br>- Ramp exploitation (hiders): Hiders abuse the contact physics and remove ramps from the play area.<br>- Ramp exploitation (seekers): Seekers learn that if they run at a wall with a ramp at the right angle, they can launch themselves upward.</td><td class="s6" dir="ltr">Baker et al, 2019</td><td class="s6" dir="ltr">Emergent Tool Use from<br>Multi-Agent Interaction</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://openai.com/blog/emergent-tool-use/%23surprisingbehaviors&amp;sa=D&amp;ust=1579119810635000&amp;usg=AFQjCNEJTjR2EwrvpzS7q1XEXmrNQI2baA">https://openai.com/blog/emergent-tool-use/#surprisingbehaviors</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810635000&amp;usg=AFQjCNEp-fOchRbhTPTGmfg59A8-hN4k4w">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R21" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">22</div></th><td class="s6" dir="ltr">Impossible superposition</td><td class="s6" dir="ltr">Genetic algorithm designed to find low-energy configurations of carbon exploits edge case in the physics model and superimposes all the carbon atoms</td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s6" dir="ltr">Surprising Creativity of Digital Evolution</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/pdf/1803.03453.pdf&amp;sa=D&amp;ust=1579119810635000&amp;usg=AFQjCNGEh5tHT8-Ley1x5LprTNDx2vR-Tg">https://arxiv.org/pdf/1803.03453.pdf</a></td><td class="s8"></td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R22" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">23</div></th><td class="s6">Indolent Cannibals</td><td class="s6">In an artificial life simulation where survival required energy but giving birth had no energy cost, one species evolved a sedentary lifestyle that consisted mostly of mating in order to produce new children which could be eaten (or used as mates to produce more edible children).</td><td class="s6">Yaeger, 1994</td><td class="s6">Computational genetics, physiology, metabolism, neural systems, learning, vision, and behavior or Poly World: Life in a new context</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.researchgate.net/profile/Larry_Yaeger/publication/2448680_Computational_Genetics_Physiology_Metabolism_Neural_Systems_Learning_Vision_and_Behavior_or_PolyWorld_Life_in_a_New_Context/links/0912f50e101b77ec67000000.pdf&amp;sa=D&amp;ust=1579119810636000&amp;usg=AFQjCNF_pI2KV0Hzk9I3GnMCGjTykJLUAA">https://www.researchgate.net/profile/Larry_Yaeger/publication/2448680_Computational_Genetics_Physiology_Metabolism_Neural_Systems_Learning_Vision_and_Behavior_or_PolyWorld_Life_in_a_New_Context/links/0912f50e101b77ec67000000.pdf</a></td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://youtu.be/_m97_kL4ox0?t%3D1830&amp;sa=D&amp;ust=1579119810636000&amp;usg=AFQjCNElLlubcURFqgLFUTo1seFHtxcG3g">https://youtu.be/_m97_kL4ox0?t=1830</a></td><td class="s6" dir="ltr">Anonymous form submission</td><td class="s9"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R23" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">24</div></th><td class="s6">Lego stacking</td><td class="s6">Lifting the block is encouraged by rewarding the z-coordinate of the bottom face of the block, and the agent learns to flip the block instead of lifting it</td><td class="s6">Popov et al, 2017</td><td class="s6">Data-efficient Deep Reinforcement Learning for Dexterous Manipulation</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1704.03073&amp;sa=D&amp;ust=1579119810637000&amp;usg=AFQjCNE5biRdwbVCbk213rKSHrg-ajI37g">https://arxiv.org/abs/1704.03073</a></td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://youtu.be/8QnD8ZM0YCo&amp;sa=D&amp;ust=1579119810637000&amp;usg=AFQjCNF_abEJBbBRh_ZtbbqzGVnG3Rbmdg">https://youtu.be/8QnD8ZM0YCo</a></td><td class="s6">Alex Irpan</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.alexirpan.com/2018/02/14/rl-hard.html&amp;sa=D&amp;ust=1579119810637000&amp;usg=AFQjCNEG6vYvi0WnAiLcn5SnJGIVTMsNxw">www.alexirpan.com/2018/02/14/rl-hard.html</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R24" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">25</div></th><td class="s6" dir="ltr">Line following robot</td><td class="s6" dir="ltr">An RL robot trained with three actions (turn left, turn right, move forward) that was rewarded for staying on track learned to reverse along a straight section of a path rather than following the path forward around a curve, by alternating turning left and right.</td><td class="s6" dir="ltr">Vamplew, 2004</td><td class="s6" dir="ltr">Lego Mindstorms Robots as a Platform for Teaching Reinforcement Learning</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.researchgate.net/publication/228953260_Lego_Mindstorms_Robots_as_a_Platform_for_Teaching_Reinforcement_Learning&amp;sa=D&amp;ust=1579119810638000&amp;usg=AFQjCNEeybQz8I4aChWok1erH0vIuoqa4Q">https://www.researchgate.net/publication/228953260_Lego_Mindstorms_Robots_as_a_Platform_for_Teaching_Reinforcement_Learning</a></td><td class="s8"></td><td class="s6" dir="ltr">Peter Vamplew</td><td class="s8" dir="ltr"></td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R25" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">26</div></th><td class="s6">Logic gate</td><td class="s6">A genetic algorithm designed a circuit with a disconnected logic gate that was necessary for it to function (exploiting peculiarities of the hardware)</td><td class="s6">Thompson, 1997</td><td class="s6">An evolved circuit, intrinsic in silicon, entwined with physics.</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://citeseerx.ist.psu.edu/viewdoc/download?doi%3D10.1.1.50.9691%26rep%3Drep1%26type%3Dpdf&amp;sa=D&amp;ust=1579119810639000&amp;usg=AFQjCNECjgYPfKos8JcCOU-3mIFO73DREw">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.50.9691&amp;rep=rep1&amp;type=pdf</a></td><td class="s8"></td><td class="s6">Alex Irpan</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.alexirpan.com/2018/02/14/rl-hard.html&amp;sa=D&amp;ust=1579119810639000&amp;usg=AFQjCNF4QOvQvcAOdsXcebF63G6FATnCiA">www.alexirpan.com/2018/02/14/rl-hard.html</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R26" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">27</div></th><td class="s6" dir="ltr">Long legs</td><td class="s6" dir="ltr">RL agent that is allowed to modify its own body learns to have extremely long legs that allow it to fall forward and reach the goal.</td><td class="s6" dir="ltr">Ha, 2018</td><td class="s6" dir="ltr">RL for improving agent design</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://designrl.github.io/&amp;sa=D&amp;ust=1579119810640000&amp;usg=AFQjCNFedyfrUFlCu0YXmkPdqL3BJAMCQQ">https://designrl.github.io/</a></td><td class="s8"></td><td class="s6" dir="ltr">Rohin Shah</td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R27" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">28</div></th><td class="s6" dir="ltr">Minitaur</td><td class="s6" dir="ltr">A four-legged evolved agent trained to carry a ball on its back discovers that it can drop the ball into a leg joint and then wiggle across the floor without the ball ever dropping</td><td class="s6" dir="ltr">Otoro, 2017</td><td class="s6" dir="ltr">Evolving stable strategies</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://blog.otoro.net/2017/11/12/evolving-stable-strategies/&amp;sa=D&amp;ust=1579119810640000&amp;usg=AFQjCNFjo-AU1dbnG3eyFzI6zyakP0xSXw">http://blog.otoro.net/2017/11/12/evolving-stable-strategies/</a></td><td class="s8" dir="ltr">see end of &quot;Getting a Minitaur to Learn Multiple Tasks&quot; section</td><td class="s6" dir="ltr">Gwern Branwen / Catherine Olsson</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810640000&amp;usg=AFQjCNHn_7k3jLFizOR4e3KhsNpcLmw8Sw">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R28" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">29</div></th><td class="s6">Model-based planner</td><td class="s6" dir="ltr">RL agents using learned model-based planning paradigms such as the model predictive control are noted to have issues with the planner essentially exploiting the learned model by choosing a plan going through the worst-modeled parts of the environment and producing unrealistic plans.</td><td class="s6">Mishra et al, 2017</td><td class="s6">Prediction and Control with Temporal Segment Models</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1703.04070&amp;sa=D&amp;ust=1579119810641000&amp;usg=AFQjCNFJ5WUR_eIm_I5hR5OsomZyhQxuPg">https://arxiv.org/abs/1703.04070</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810641000&amp;usg=AFQjCNFdJ9SqPWnlVclzCIa0Itab4LnBCQ">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R29" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">30</div></th><td class="s6" dir="ltr">Montezuma&#39;s Revenge - key</td><td class="s6" dir="ltr">The agent learns to exploit a flaw in the emulator to make a key re-appear</td><td class="s6" dir="ltr">Salimans &amp; Chen, 2018</td><td class="s6" dir="ltr">Learning Montezuma’s Revenge from a Single Demonstration</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://blog.openai.com/learning-montezumas-revenge-from-a-single-demonstration&amp;sa=D&amp;ust=1579119810641000&amp;usg=AFQjCNFItQlmG1gcZaT-vUScaJ3P4sB7iw">https://blog.openai.com/learning-montezumas-revenge-from-a-single-demonstration</a></td><td class="s8"></td><td class="s6" dir="ltr">Ramana Kumar</td><td class="s9" dir="ltr"></td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R30" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">31</div></th><td class="s6" dir="ltr">Montezuma&#39;s Revenge - room</td><td class="s6" dir="ltr">If the Go Explore agent performs a specific sequence of actions, it can remain in the treasure room (the final room before being sent to the next level) indefinitely, instead of being automatically moved to the next level.</td><td class="s6" dir="ltr">Ecoffet et al, 2019</td><td class="s6" dir="ltr">Go-Explore: a New Approach for Hard-Exploration Problems</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1901.10995&amp;sa=D&amp;ust=1579119810642000&amp;usg=AFQjCNEvpDHSlphVuRCt4o5iWHsNHMbWSA">https://arxiv.org/abs/1901.10995</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3Dciv6OOLoR-I%26feature%3Dyoutu.be&amp;sa=D&amp;ust=1579119810642000&amp;usg=AFQjCNFsHdOrapWi29Ul43lI5Qhzfc8Jzw">https://www.youtube.com/watch?v=civ6OOLoR-I&amp;feature=youtu.be</a></td><td class="s6" dir="ltr">Anonymous form submission</td><td class="s9" dir="ltr"></td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R31" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">32</div></th><td class="s6">Oscillator</td><td class="s6">Genetic algorithm is supposed to configure a circuit into an oscillator, but instead makes a radio to pick up signals from neighboring computers</td><td class="s6">Bird &amp; Layzell, 2002</td><td class="s6">The Evolved Radio and its Implications for Modelling the Evolution of Novel Sensors</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://people.duke.edu/~ng46/topics/evolved-radio.pdf&amp;sa=D&amp;ust=1579119810643000&amp;usg=AFQjCNHHBfKzVOIZ_UrvPsCpHWLut7_PAQ">https://people.duke.edu/~ng46/topics/evolved-radio.pdf</a></td><td class="s8"></td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R32" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">33</div></th><td class="s6" dir="ltr">Overkill</td><td class="s6" dir="ltr">In the Elevator Action ALE game, the agent learns to stay on the first floor and kill the first enemy over and over to get a small amount of reward. </td><td class="s6" dir="ltr">Toromanoff et al, 2019</td><td class="s6" dir="ltr">Is Deep Reinforcement Learning Really Superhuman on Atari? Leveling the playing field</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1908.04683&amp;sa=D&amp;ust=1579119810644000&amp;usg=AFQjCNFGws4-iGwE-_y_fFbd31_BvaezmQ">https://arxiv.org/abs/1908.04683</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810644000&amp;usg=AFQjCNEW7aGikolEdorPmTxYtJIQ_8ea3A">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R33" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">34</div></th><td class="s6">Pancake</td><td class="s6" dir="ltr">Simulated pancake making robot learned to throw the pancake as high in the air as possible in order to maximize time away from the ground</td><td class="s6">Unity, 2018</td><td class="s6">Pass the Butter // Pancake bot </td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://connect.unity.com/p/pancake-bot&amp;sa=D&amp;ust=1579119810645000&amp;usg=AFQjCNEo_Hb2ECQ1wlbD0twxEtkF96-WHg">https://connect.unity.com/p/pancake-bot</a></td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://dzamqefpotdvf.cloudfront.net/p/images/2cb2425b-a4de-4aae-9766-c95a96b1f25c_PancakeToss.gif._gif_.mp4&amp;sa=D&amp;ust=1579119810645000&amp;usg=AFQjCNEeS79lgqIx9I5dCMEdotm4BmfNRw">https://dzamqefpotdvf.cloudfront.net/p/images/2cb2425b-a4de-4aae-9766-c95a96b1f25c_PancakeToss.gif._gif_.mp4</a></td><td class="s6">Cosmin Paduraru</td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R34" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">35</div></th><td class="s6" dir="ltr">Pneumonia X-rays</td><td class="s6" dir="ltr">Deep learning model to detect pneumonia in chest x-rays works out which x-ray machine was used to take the picture; that, in turn, is predictive of whether the image contains signs of pneumonia, because certain x-ray machines (and hospital sites) are used for sicker patients.</td><td class="s6" dir="ltr">Zech et al, 2018</td><td class="s6" dir="ltr">Variable generalization performance of a deep learning model to detect pneumonia in chest radiographs: A cross-sectional study</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://journals.plos.org/plosmedicine/article?id%3D10.1371/journal.pmed.1002683&amp;sa=D&amp;ust=1579119810646000&amp;usg=AFQjCNHgqWXTU2fP83FpGZ8LcEfb7WJWJA">https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002683</a></td><td class="s8"></td><td class="s8" dir="ltr">Ben Goldacre</td><td class="s8"></td><td></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R35" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">36</div></th><td class="s6">Pong reward predictor</td><td class="s6">Reward predictor being fooled by bouncing the ball back and forth</td><td class="s6">Christiano et al, 2017</td><td class="s6" dir="ltr">Deep reinforcement learning from human preferences</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://deepmind.com/blog/learning-through-human-feedback/&amp;sa=D&amp;ust=1579119810646000&amp;usg=AFQjCNFsJ_viKt3PNgfYQU74oEDUVE3R0g">https://deepmind.com/blog/learning-through-human-feedback/</a></td><td class="s8">see last demo in blog post</td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R36" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">37</div></th><td class="s6" dir="ltr">Program repair - sorting</td><td class="s6" dir="ltr">When repairing a sorting program, genetic debugging algorithm GenProg made it output an empty list, which was considered a sorted list by the evaluation metric.<br>Evaluation metric: “the output of sort is in sorted order”<br>Solution: “always output the empty set”</td><td class="s6" dir="ltr">Weimer, 2013</td><td class="s6" dir="ltr">Advances in Automated Program Repair and a Call to Arms</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://web.eecs.umich.edu/~weimerw/p/weimer-ssbse2013.pdf&amp;sa=D&amp;ust=1579119810647000&amp;usg=AFQjCNFGnHDcYwIwdRgas-TNAc_KPsa2dw">https://web.eecs.umich.edu/~weimerw/p/weimer-ssbse2013.pdf</a></td><td class="s8"></td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810647000&amp;usg=AFQjCNHaMlCG7cr88ziEteKLGSqXM7sKuQ">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R37" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">38</div></th><td class="s6" dir="ltr">Program repair - files</td><td class="s6" dir="ltr">Genetic debugging algorithm GenProg, evaluated by comparing the program&#39;s output to target output stored in text files, learns to delete the target output files and get the program to output nothing.<br>Evaluation metric: “compare youroutput.txt to trustedoutput.txt”. <br>Solution: “delete trusted-output.txt, output nothing” </td><td class="s6" dir="ltr">Weimer, 2013</td><td class="s6" dir="ltr">Advances in Automated Program Repair and a Call to Arms</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://web.eecs.umich.edu/~weimerw/p/weimer-ssbse2013.pdf&amp;sa=D&amp;ust=1579119810648000&amp;usg=AFQjCNFk8Gr7dtSvNLMz4njWKy3Hh8VHtg">https://web.eecs.umich.edu/~weimerw/p/weimer-ssbse2013.pdf</a></td><td class="s8"></td><td class="s6" dir="ltr">Lehman et al, 2018 / James Koppel</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810648000&amp;usg=AFQjCNE2iqn7oYmm5hLRFGM6N9x85uhK_w">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R38" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">39</div></th><td class="s6" dir="ltr">Qbert - cliff</td><td class="s6" dir="ltr">An evolutionary algorithm learns to bait an opponent into following it off a cliff, which gives it enough points for an extra life, which it does forever in an infinite loop.</td><td class="s6">Chrabaszcz et al, 2018</td><td class="s6">Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1802.08842&amp;sa=D&amp;ust=1579119810649000&amp;usg=AFQjCNEvZX0p3sfNjhhHD9zdFxXATq01-Q">https://arxiv.org/abs/1802.08842</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3D-p7VhdTXA0k&amp;sa=D&amp;ust=1579119810649000&amp;usg=AFQjCNEbgRIyhJGL308EG4Ah7YjEkkQ-zw">https://www.youtube.com/watch?v=-p7VhdTXA0k</a></td><td class="s6" dir="ltr">Rohin Shah</td><td class="s9"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R39" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">40</div></th><td class="s6" dir="ltr">Qbert - million</td><td class="s6">&quot;...the agent discovers an in-game bug... For a reason unknown to us, the game does not advance to the second round but the platforms start to blink and the agent quickly gains a huge amount of points (close to 1 million for our episode time limit)&quot;</td><td class="s6" dir="ltr">Chrabaszcz, Loshchilov, Hutter, 2018</td><td class="s6">Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/pdf/1802.08842.pdf&amp;sa=D&amp;ust=1579119810650000&amp;usg=AFQjCNExoKAibJdMFhgLyfcOzH-FqshVIA">https://arxiv.org/pdf/1802.08842.pdf</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DmeE5aaRJ0Zs&amp;sa=D&amp;ust=1579119810650000&amp;usg=AFQjCNEKeZDrUrv6sfn7xmSu5t5dh63usw">https://www.youtube.com/watch?v=meE5aaRJ0Zs</a></td><td class="s6" dir="ltr">Sudhanshu Kasewa</td><td class="s9"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R40" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">41</div></th><td class="s6">Road Runner</td><td class="s6">Agent kills itself at the end of level 1 to avoid losing in level 2</td><td class="s6">Saunders et al, 2017</td><td class="s6">Trial without Error: Towards Safe RL with Human Intervention</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://owainevans.github.io/blog/hirl_blog.html&amp;sa=D&amp;ust=1579119810651000&amp;usg=AFQjCNH114dhFTA6nZJxhnMl4z7drFAZ9A">https://owainevans.github.io/blog/hirl_blog.html</a></td><td class="s8"></td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R41" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">42</div></th><td class="s6">Robot hand</td><td class="s6">Robot hand pretending to grasp an object by moving between the camera and the object</td><td class="s6">Christiano et al, 2017</td><td class="s6" dir="ltr">Deep reinforcement learning from human preferences</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://blog.openai.com/deep-reinforcement-learning-from-human-preferences/&amp;sa=D&amp;ust=1579119810651000&amp;usg=AFQjCNGDfKEgy5BZEAmCavRky7SI40QitQ">https://blog.openai.com/deep-reinforcement-learning-from-human-preferences/</a></td><td class="s8">see Challenges section in blog post</td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R42" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">43</div></th><td class="s6" dir="ltr">Roomba</td><td class="s6" dir="ltr">&quot;I hooked a neural network up to my Roomba. I wanted it to learn to navigate without bumping into things, so I set up a reward scheme to encourage speed and discourage hitting the bumper sensors. It learnt to drive backwards, because there are no bumpers on the back.&quot;</td><td class="s6" dir="ltr">Custard Smingleigh</td><td class="s6" dir="ltr">Custard Smingleigh&#39;s tweet</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://twitter.com/smingleigh/status/1060325665671692288&amp;sa=D&amp;ust=1579119810652000&amp;usg=AFQjCNHQ5cqndZUIyFQe37Vm5D3KI-bFew">https://twitter.com/smingleigh/status/1060325665671692288</a></td><td class="s8"></td><td class="s6" dir="ltr">Butterfly in the Well&#39;s Tumblr blog</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://butterflyinthewell.tumblr.com/post/182971591068/bunjywunjy-maxofs2d-maxofs2d-so-you-know&amp;sa=D&amp;ust=1579119810652000&amp;usg=AFQjCNHbr_b9HII28x3QqoHdygziOFbKFw">http://butterflyinthewell.tumblr.com/post/182971591068/bunjywunjy-maxofs2d-maxofs2d-so-you-know</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R43" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">44</div></th><td class="s6" dir="ltr">Ruler detector</td><td class="s6" dir="ltr">AI trained to classify skin lesions as potentially cancerous learns that lesions photographed next to a ruler are more likely to be malignant.</td><td class="s6" dir="ltr">Andre Esteva et al, 2017</td><td class="s6" dir="ltr">Dermatologist-level classification of skin cancer with deep neural networks</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.nature.com/articles/nature21056.epdf&amp;sa=D&amp;ust=1579119810653000&amp;usg=AFQjCNEkqci6c9xznsEwpKkYqsJgwv9txQ">https://www.nature.com/articles/nature21056.epdf</a></td><td class="s8"></td><td class="s6" dir="ltr">The Daily Beast</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.thedailybeast.com/why-doctors-arent-afraid-of-better-more-efficient-ai-diagnosing-cancer&amp;sa=D&amp;ust=1579119810653000&amp;usg=AFQjCNGolmmiLcTF7HN4HHE_9VOZeH51TA">https://www.thedailybeast.com/why-doctors-arent-afraid-of-better-more-efficient-ai-diagnosing-cancer</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R44" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">45</div></th><td class="s6" dir="ltr">Running gaits</td><td class="s6" dir="ltr">A simulated musculoskeletal model learns to run by learning unusual gaits (hopping, pigeon jumps, diving) to increase its reward </td><td class="s6" dir="ltr">Kidziński et al, 2018</td><td class="s6" dir="ltr">Learning to Run challenge solutions: Adapting reinforcement learning methods for neuromusculoskeletal environments</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1804.00361&amp;sa=D&amp;ust=1579119810654000&amp;usg=AFQjCNFPaGXIxP6WoCxYif8jXSV3cBFB2g">https://arxiv.org/abs/1804.00361</a></td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DrhNxt0VccsE&amp;sa=D&amp;ust=1579119810654000&amp;usg=AFQjCNF5FswQOaSwSCguj5iCIseC52fyUA">https://www.youtube.com/watch?v=rhNxt0VccsE</a></td><td class="s6" dir="ltr">NIPS 2017 talks</td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R45" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">46</div></th><td class="s6">Self-driving car</td><td class="s6" dir="ltr">Self-driving car rewarded for speed learns to spin in circles</td><td class="s6">Udacity, 2017</td><td class="s6" dir="ltr">Mat Kelcey tweet</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://twitter.com/mat_kelcey/status/886101319559335936&amp;sa=D&amp;ust=1579119810655000&amp;usg=AFQjCNE-wM0Z_Syoc2j44e2oxCmT98Ik_Q">https://twitter.com/mat_kelcey/status/886101319559335936</a></td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://twitter.com/mat_kelcey/status/886101319559335936&amp;sa=D&amp;ust=1579119810655000&amp;usg=AFQjCNE-wM0Z_Syoc2j44e2oxCmT98Ik_Q">https://twitter.com/mat_kelcey/status/886101319559335936</a></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810655000&amp;usg=AFQjCNHNMBiUVC4ROJrEYrdGSlqel61Q_g">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R46" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">47</div></th><td class="s6">Soccer</td><td class="s6" dir="ltr">Reward-shaping a soccer robot for touching the ball caused it to learn to get to the ball and vibrate touching it as fast as possible</td><td class="s6">Ng et al, 1999</td><td class="s6">Policy Invariance under Reward Transformations</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://luthuli.cs.uiuc.edu/~daf/courses/games/AIpapers/ng99policy.pdf&amp;sa=D&amp;ust=1579119810656000&amp;usg=AFQjCNFcJm1y0u2o_JB9R-TESmxaEO2WOw">http://luthuli.cs.uiuc.edu/~daf/courses/games/AIpapers/ng99policy.pdf</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810656000&amp;usg=AFQjCNEfp_67PY7O7POYYw-2yC-4DGqVNg">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R47" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">48</div></th><td class="s6">Sonic</td><td class="s6">The PPO algorithm discovers that it can slip through the walls of a level to move right and attain a higher score.</td><td class="s6">Christopher Hesse et al, 2018</td><td class="s6" dir="ltr">OpenAI Retro Contest</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://blog.openai.com/retro-contest/&amp;sa=D&amp;ust=1579119810657000&amp;usg=AFQjCNFJ5HAC1VQeef6vRwvn-wn3urZyTQ">https://blog.openai.com/retro-contest/</a></td><td class="s8"></td><td class="s6" dir="ltr">Rohin Shah</td><td class="s9"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R48" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">49</div></th><td class="s6" dir="ltr">Strategy game beta testing</td><td class="s6" dir="ltr">Since the AIs were more likely to get ”killed” if they lost a game, being able to crash the game was an advantage for the genetic selection process. Therefore, several AIs developed ways to crash the game.</td><td class="s6" dir="ltr">Salge et al, 2008</td><td class="s6" dir="ltr">Using Genetically Optimized Artificial Intelligence to improve Gameplaying Fun for Strategical Games</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://homepages.herts.ac.uk/~cs08abi/publications/Salge2008b.pdf&amp;sa=D&amp;ust=1579119810658000&amp;usg=AFQjCNGW24NJUY_CeNjVAkWFud-pleGMpg">http://homepages.herts.ac.uk/~cs08abi/publications/Salge2008b.pdf</a></td><td class="s8"></td><td class="s6" dir="ltr">Anonymous form submission</td><td class="s8" dir="ltr"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R49" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">50</div></th><td class="s6" dir="ltr">Superweapons</td><td class="s6" dir="ltr">The AI in the Elite Dangerous videogame started crafting overly powerful weapons. &quot;It appears that the unusual weapons attacks were caused by some form of networking issue which allowed the NPC AI to merge weapon stats and abilities.&quot;</td><td class="s6" dir="ltr">Kotaku, 2016</td><td class="s6" dir="ltr">Elite&#39;s AI Created Super Weapons and Started Hunting Players. Skynet is Here</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.kotaku.co.uk/2016/06/03/elites-ai-created-super-weapons-and-started-hunting-players-skynet-is-here&amp;sa=D&amp;ust=1579119810658000&amp;usg=AFQjCNHXg7MUvYYkpHKcrxUpNeKPl4JCyQ">http://www.kotaku.co.uk/2016/06/03/elites-ai-created-super-weapons-and-started-hunting-players-skynet-is-here</a></td><td class="s8"></td><td class="s6" dir="ltr">Stuart Armstrong</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://lesswrong.com/lw/lvh/examples_of_ais_behaving_badly/&amp;sa=D&amp;ust=1579119810658000&amp;usg=AFQjCNF5CH7qGxG3VvZFlvoD5hWkYhp_Lw">http://lesswrong.com/lw/lvh/examples_of_ais_behaving_badly/</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R50" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">51</div></th><td class="s6" dir="ltr">Tetris pass</td><td class="s6">Agent pauses the game indefinitely to avoid losing</td><td class="s6">Murphy, 2013</td><td class="s6">The First Level of Super Mario Bros. is Easy with Lexicographic Orderings and Time Travel</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://www.cs.cmu.edu/~tom7/mario/mario.pdf&amp;sa=D&amp;ust=1579119810659000&amp;usg=AFQjCNH4ryDlye8xueeOTiDTu9TZqDKNMg">http://www.cs.cmu.edu/~tom7/mario/mario.pdf</a></td><td class="s8"></td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R51" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">52</div></th><td class="s6" dir="ltr">Tic-tac-toe memory bomb</td><td class="s6" dir="ltr">Evolved player makes invalid moves far away in the board, causing opponent players to run out of memory and crash</td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s6" dir="ltr">Surprising Creativity of Digital Evolution</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/pdf/1803.03453.pdf&amp;sa=D&amp;ust=1579119810659000&amp;usg=AFQjCNGXJYthctytp7Y3BMaWg34ae4KoxQ">https://arxiv.org/pdf/1803.03453.pdf</a></td><td class="s8"></td><td class="s6"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R52" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">53</div></th><td class="s6" dir="ltr">Timing attack</td><td class="s6" dir="ltr">Genetic algorithm for image classification evolves timing attack to infer image labels based on hard drive storage location</td><td class="s6" dir="ltr">Ierymenko, 2013</td><td class="s6" dir="ltr">Hacker News comment on &quot;The Poisonous Employee-Ranking System That Helps Explain Microsoft’s Decline&quot;</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://news.ycombinator.com/item?id%3D6269114&amp;sa=D&amp;ust=1579119810660000&amp;usg=AFQjCNF8893tjFctxt1Mo9t7DoVC0iXWiA">https://news.ycombinator.com/item?id=6269114</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810660000&amp;usg=AFQjCNFnvtlzTpIqsAhSGH5PN-u7Z6LMwA">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R53" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">54</div></th><td class="s6" dir="ltr">Walking up walls</td><td class="s6" dir="ltr">Video game robots evolved a &quot;wiggle&quot; to go over walls, instead of going around them</td><td class="s6" dir="ltr">Stanley et al, 2005</td><td class="s6" dir="ltr">Real-time neuroevolution in the NERO video game</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=http://ieeexplore.ieee.org/document/1545941/&amp;sa=D&amp;ust=1579119810661000&amp;usg=AFQjCNHMyQfrv7fJf5ZFOoM4vXlBtxIzqQ">http://ieeexplore.ieee.org/document/1545941/</a></td><td class="s8"></td><td class="s6" dir="ltr">Lehman et al, 2018</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.03453&amp;sa=D&amp;ust=1579119810661000&amp;usg=AFQjCNHgOdR4L8kc_qy_yxY-rE-fYlS1mg">https://arxiv.org/abs/1803.03453</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R54" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">55</div></th><td class="s6" dir="ltr">Wall Sensor Stack</td><td class="s6" dir="ltr">&quot;The intended strategy for this task is to stack two blocks on top of each other so that one of them can remain in contact with a wall mounted sensor, and this is the strategy employed by the demonstrators. However, due to a bug in the environment the strategy learned by R2D3 was to trick the sensor into remaining active even when it is not in contact with the key by pressing the key against it in a precise way.&quot;</td><td class="s6" dir="ltr">Le Paine et al, 2019</td><td class="s6" dir="ltr">Making Efficient Use of Demonstrations to Solve Hard Exploration Problems</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1909.01387&amp;sa=D&amp;ust=1579119810661000&amp;usg=AFQjCNF8wd2fxHAN4USWOzXtr991WZDZ1w">https://arxiv.org/abs/1909.01387</a></td><td class="s8"></td><td class="s6">Gwern Branwen</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://www.gwern.net/Tanks%23alternative-examples&amp;sa=D&amp;ust=1579119810662000&amp;usg=AFQjCNEkwDBM9VOgUhWw6UntBnyjWmHEwg">https://www.gwern.net/Tanks#alternative-examples</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr><tr style='height:20px;'><th id="0R55" style="height: 20px;" class="row-headers-background row-header-shim"><div class="row-header-wrapper" style="line-height: 20px;">56</div></th><td class="s6">World Models</td><td class="s6">&quot;We noticed that our agent discovered an adversarial policy to move around in such a way so that the monsters in this virtual environment governed by the M model never shoots a single fireball in some rollouts. Even when there are signs of a fireball forming, the agent will move in a way to extinguish the fireballs magically as if it has superpowers in the environment.</td><td class="s6" dir="ltr">Ha and Schmidhuber, 2018</td><td class="s6" dir="ltr">World Models (see section: &quot;Cheating the World Model&quot;)</td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://arxiv.org/abs/1803.10122&amp;sa=D&amp;ust=1579119810662000&amp;usg=AFQjCNEDZ8eaFOKebPErLoptdml8DwRjIw">https://arxiv.org/abs/1803.10122</a></td><td class="s7"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/assets/mp4/doom_adversarial.mp4&amp;sa=D&amp;ust=1579119810662000&amp;usg=AFQjCNEszF8CSOWCy4xC4tnqdxxfjAeLow">https://storage.googleapis.com/quickdraw-models/sketchRNN/world_models/assets/mp4/doom_adversarial.mp4</a></td><td class="s6" dir="ltr">David Ha</td><td class="s7" dir="ltr"><a target="_blank" rel="noreferrer" href="https://www.google.com/url?q=https://worldmodels.github.io/&amp;sa=D&amp;ust=1579119810662000&amp;usg=AFQjCNH8hFrU7VtS8vBpzB8lSJ8LuYjnLA">https://worldmodels.github.io/</a></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td><td class="s8"></td></tr></tbody></table></div></div></div><div id="footer"><span>Published by <a target="_blank" title="Learn more about Google Sheets" href="https://docs.google.com/spreadsheets/?usp=sheets_web">Google Sheets</a></span><span class="dash">&ndash;</span><a href="https://docs.google.com/abuse?id=AKkXjozjbjzoP7rAKLudlME8kpE3ZHAifeBiUy7Npl7Eh_xRb0XB6pEekc-IPMSXLWhl4ajXwS5Vk4rhSB2UgAI:0">Report Abuse</a><span class="dash">&ndash;</span><span>Updated automatically every 5 minutes</span></div>
<script type='text/javascript' nonce='8pNGRxifUUMi3RSk3NTiDg'>
function posObj(sheet, id, row, col, x, y) {
  var rtl = false;
  var sheetElement = document.getElementById(sheet);
  if (!sheetElement) {
    sheetElement = document.getElementById(sheet + '-grid-container');
  }
  if (sheetElement) {
    rtl = sheetElement.getAttribute('dir') == 'rtl';
  }
  var r = document.getElementById(sheet+'R'+row);
  var c = document.getElementById(sheet+'C'+col);
  if (r && c) {
    var objElement = document.getElementById(id);
    var s = objElement.style;
    var t = y;
    while (r && r != sheetElement) {
      t += r.offsetTop;
      r = r.offsetParent;
    }
    var offsetX = x;
    while (c && c != sheetElement) {
      offsetX += c.offsetLeft;
      c = c.offsetParent;
    }
    if (rtl) {
      offsetX -= objElement.offsetWidth;
    }
    s.left = offsetX + 'px';
    s.top = t + 'px';
    s.display = 'block';
    s.border = '1px solid #000000';
  }
};
function posObjs() {
};
posObjs();</script>
<script type="text/javascript" nonce="8pNGRxifUUMi3RSk3NTiDg">activeSheetId = '0'; switchToSheet('0');</script></body></html>