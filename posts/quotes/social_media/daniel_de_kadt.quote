## daniel_de_kadt.quote -*- mode: fundamental-mode -*-
# Summary:
#
#
#
Great question. Here's how I try to approach an observational causal inference project.

Goal is to fail fast if the project isn't feasible.

O. Assume you have a well defined question (at minimum a D and Y), a simple theory (how D and Y
are connected), and a plausible design.

1. Sketch Minimum Viable Product (MVP)

- sketch simplest version of design
- find the quantity of interest (Qol)
- write down simple estimator for Qol
- sketch minimal data table req'd (literally, draw a mock table in pen).

Ask: is the MVP doable?

If yes, continue. If no, end.

2. Extend the MVP

- figure out a few strong falsification tests for the design
- amend your MVP data table to allow for these if needed
- *do not* be tempted to expand the MVP in any other way - mission creep is the enemy!

Keep it simple, keep it minimal!

3. Build the MVP:

- Go out and get the data req'd to make the MVP data table
- Do not be tempted by perfection or expansion at this stage
- Run your falsification tests

If fail, return to step 1. If pass, continue.

- Estimate MVP Qol

If the MVP "works", continue. If not, end.

The rest is more laborious but also easier, as you know you have something likely viable:

4. Design the actual product
- expand beyond the MVP
- think of interesting additional tests and data
-etc

5. Build the actual product

6. Start writing. Iterate 4-6. Etc.

Caveat 1: I haven't mentioned anything about pre-registration or power analyses. These could
come at the end of the MVP stage (before estimation) - you might do them as a way to assess
fund feasibility.

But for observational data they are often really hard to do, ime.

Caveat 2: What does it mean for an MVP to "work?"

Well, to me it means that there is (a) a feasible design that should be taken seriously, and (b) there
is signal in the data, not just noise. Null effects are fine, but noisy, highly variable/sensitive results,
less so.

Caveat 3: For your own sanity, you want to balance two things as you build an MVP: minimalism
and DRY coding. Minimalism means doing as little as you can to figure out if the project is a go. But
Don't Repeat Yourself - don't just write garbage code that can't be used later.



[quote @_AlvinChristian]:
Any advice on "starting" a research project?
I have a hard time following through after coming up with a question and a potential research
design. It feels analogous to staring at a blank page when you're supposed to be writing.
